{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as  np\n",
    "import scipy.io as  l\n",
    "import os, sys\n",
    "top_dir = os.getcwd().split('v4cnn')[0]\n",
    "sys.path.append(top_dir + 'xarray')\n",
    "top_dir = top_dir+ 'v4cnn/'\n",
    "sys.path.append(top_dir)\n",
    "sys.path.append(top_dir + 'common')\n",
    "\n",
    "import xarray as xr\n",
    "import d_misc as dm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will do our permuting of cell responses over position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def permute_unit(unit):\n",
    "    unit = unit.dropna('x', 'all').dropna('shapes', 'all')\n",
    "    for x in range(len(unit.coords['x'])):\n",
    "        unit[x,:] = np.random.permutation(unit[x,:].values)\n",
    "    return unit \n",
    "def permute_unit_array(unit):\n",
    "    for x in range(np.shape(unit)[1]):\n",
    "        unit[:,x] = np.random.permutation(unit[:,x])\n",
    "    return unit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is the core of the TI measurement.\n",
    "\n",
    "It measures the fit of a unit's matrix $R$ of responses over position and stimuli, that can be accounted for by the outer product of a receptive field $\\vec{f}$, and  stimuli response profile $\\vec{s}$. \n",
    "$$ R = \\vec{f} \\otimes \\vec{s} $$\n",
    "We do this using SVD, for the $m$ shapes, and $n$ positions where typically $m>n$. We construct an $m \\ x \\ n$ matrix $R$\n",
    "\n",
    "For which we decompose using SVD:\n",
    "$$ R = U \\Sigma V $$\n",
    "\n",
    "$U$ is $m \\ x \\ n$, its columns are eigenvectors of $R$, and the 1st column is the least squares estimate of $\\vec{s}$.\n",
    "\n",
    "V is $n \\ x \\ n$, its rows are eigenvectors of $R$, and the first column is a least squares estimate of $\\vec{f}$.\n",
    "\n",
    "$\\Sigma$ is $n \\ x \\ n$ where $\\Sigma_{ii}=\\sigma_i$ are the sorted singular values of $R$, $\\sigma_1$ is the smallest possible value of  $\\sqrt{ \\sum  (R - \\vec{f} \\otimes \\vec{s})^2}$\n",
    "\n",
    "Finally we take as our measure of fit to the TI model we will call TIA:\n",
    "$$\\frac{\\sigma_1^2}{\\sum \\sigma_i^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure_TIA(unit):\n",
    "    unit = unit.dropna('x', 'all').dropna('shapes', 'all')\n",
    "    tot_var = (unit**2).sum()\n",
    "    s = np.linalg.svd(unit.values, compute_uv=False)[0]\n",
    "    return (s**2)/np.sum(s**2)\n",
    "#this is just for units that are not in a fancy data structure\n",
    "def measure_TIA_array(unit):\n",
    "    tot_var = np.sum((unit**2))\n",
    "    s = np.linalg.svd(unit, compute_uv=False)\n",
    "    return (s[0]**2)/np.sum(s**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately TIA has problems with overfitting.\n",
    "For example if we take response that has no translation invariance, i.e. each column is orthogonal TIA will not give it a score of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  0.  0.  0.  0.]\n",
      " [ 0.  2.  0.  0.  0.]\n",
      " [ 0.  0.  2.  0.  0.]\n",
      " [ 0.  0.  0.  2.  0.]\n",
      " [ 0.  0.  0.  0.  2.]]\n",
      "TIA = 0.2\n"
     ]
    }
   ],
   "source": [
    "unit = np.eye(5)*2\n",
    "print(unit)\n",
    "print('TIA = ' + str(measure_TIA_array(unit)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It instead gives TIA of 0.2, why is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The singular values of our unit:\n",
      "[ 2.  2.  2.  2.  2.]\n"
     ]
    }
   ],
   "source": [
    "print('The singular values of our unit:')\n",
    "print(np.linalg.svd(unit, compute_uv=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the SVD guarantees only that $$\\sigma_1 \\ge \\dots \\ge \\sigma_n$$ and in the above case $$\\sigma_1 = \\dots = \\sigma_n$$ where $\\sigma_1$ accounts for $\\frac{1}{n}$ of the variance of a matrix, where $n$ is the number of positions, the smallest it possibly can be. This is uniquely the case where all columns of our matrix have equal length and are orthogonal.\n",
    "In this case $TIA>=\\frac{1}{n}$, our metric cannot reach 0. In addition TIA depends on the number of positions measured another severe shortcoming.\n",
    "\n",
    "To correct for this in general we can try to figure out, for the type of matrices we are dealing with, what $F$ is where $TIA>=F$\n",
    "\n",
    "Then we get a normalized value $$TIN = \\frac{TIA-F}{(1-F)}$$\n",
    "\n",
    "If for example we take $F = \\frac{1}{n}$ we are guranteed that TIN over all possible response matrices will range between 0, and 1. Lets check for our previous matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIA = 0.2\n",
      "TIN = 0.0\n"
     ]
    }
   ],
   "source": [
    "unit = np.eye(5)\n",
    "TIA = measure_TIA_array(unit)\n",
    "F = 1./len(unit[:,])\n",
    "TIN = (TIA-F)/((1-F))\n",
    "print('TIA = ' + str(TIA))\n",
    "print('TIN = '+ str(TIN))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Great! Going forward in the spirit of our normalization we want to be able to make a fair comparison between responses of different RF and SP, such that a particular RF or SP doesn't inherently give the TI measure an advantage. In other words given an RF and SF we want the F that is the minimal possible TI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Non-Uniform RF</h4>\n",
    "\n",
    "While $F = \\frac{1}{n}$ works in the previous case lets look at the case where we know our matrix does not have column vectors of equal length i.e. a non-uniform RF. Here we are essentially trying to remove receptive field size as a factor in TI i.e. just because two cells have different RF sizes, doesn't mean one should get better TI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit responses:\n",
      "[[ 0.  1.  1.  0.]\n",
      " [ 0.  1. -1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1. -1.  0.]]\n",
      "RF:\n",
      "[ 0.  4.  4.  0.]\n"
     ]
    }
   ],
   "source": [
    "unit = np.zeros((4,4))\n",
    "unit[:,1] = 1\n",
    "unit[:,2] = [1,-1,1,-1]\n",
    "\n",
    "print('Unit responses:')\n",
    "print(unit)\n",
    "print('RF:')\n",
    "print(np.sum(unit**2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the cell has a non-uniform RF.\n",
    "\n",
    "Keep in mind again the columns are orthogonal so intuitively we should expect a translation invariance of 0.\n",
    "\n",
    "What is our measure of TIA and TIN where $F = \\frac{1}{n}$, for this response matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F=0.25\n",
      "TIA = 0.5\n",
      "TIN = 0.333333333333\n",
      "The singular values=\n",
      "[ 2.  2.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "TIA = measure_TIA_array(unit)\n",
    "F = 1./len(unit[:,])\n",
    "print('F=' + str(F))\n",
    "TIN = (TIA-F)/(1-F)\n",
    "print('TIA = ' + str(TIA))\n",
    "print('TIN = '+ str(TIN))\n",
    "print('The singular values=')\n",
    "print(np.linalg.svd(unit, compute_uv=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terrible! It seems a non-translation invariant cell can take on translation invariance simply with a non-uniform receptive field, in this case a compact receptive field. \n",
    "\n",
    "Even if our columns are orthogonal $\\sigma_1$ will simply equal the magnitude of the greatest response position, or the center of the RF.\n",
    "\n",
    "In the case of all response matrices with non-uniform RF's what F do we need?\n",
    "$$F = \\frac{max_i(\\sum\\limits_{j=1}^m R_{i,j}^2)}{\\sum\\limits_{i,j}^{m,n} R_{i,j}^2}$$\n",
    "\n",
    "The variance of the position with the greatest variance divided by the total variance. \n",
    "\n",
    "Lets see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  1.  0.]\n",
      " [ 0.  1. -1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1. -1.  0.]]\n",
      "TIA = 0.5\n",
      "TIN = 2.22044604925e-16\n"
     ]
    }
   ],
   "source": [
    "print(unit)\n",
    "TIA = measure_TIA_array(unit)\n",
    "F = max(np.sum(unit**2,0))/np.sum(unit**2)\n",
    "TIN = (TIA-F)/(1-F)\n",
    "print('TIA = ' + str(TIA))\n",
    "print('TIN = '+ str(TIN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! The intuition behind this correction is that if we only know the length of each column vector, the direction of those vectors is still free to vary. With direction freely varying but length fixed vectors, what is the minimal singular value they could take on? It is the case where all columns are orthogonal to each other, and in this case the principal component will take on the direction of the longest vector, and will account for only its variance (because all other columns are orthogonal to it).\n",
    "Now lets try to add on one more constraint the SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Matrix:\n",
      "[[ 10.   0.]\n",
      " [  0.   2.]]\n",
      "Our estimated stimuli profile\n",
      "[[ 1.]\n",
      " [ 0.]]\n",
      "Our estimated receptive field\n",
      "[ 1.  0.]\n",
      "Our singular values\n",
      "[ 10.   2.]\n",
      "Our estimated TI response\n",
      "[[ 10.   0.]\n",
      " [  0.   0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFK1JREFUeJzt3X+MHGd9x/HPd+0e2lCkcDg680uJCyFuIgprEApyKp9a\n7tagNuXstpCI6koiAiJFND0qxw3gK76TE7UXUCk/5DRxLEGMkNAhI8Ktj6iXYlpRkru6boJJoEmU\nkNjEuFVFe8JJ7ts/ZvZub293vbO7c7v77PslrW5nZnfnmZuZzz7zzDOz5u4CAIQp0+4CAADSQ8gD\nQMAIeQAIGCEPAAEj5AEgYIQ8AASs6ZA3s3vM7IyZnSwZ129ms2b2mJkdM7OLm50PACC5VtTkD0na\nWTbuVkmz7v4mSQ/EwwCAdWatuBjKzC6T9C13f3M8fErSDnc/Y2abJc25+9amZwQASCStNvkBdz8T\nPz8jaSCl+QAAakj9xKtHhwrcOwEA2mBjSp97xsw2u/tpM3u1pJ+Xv8DMCH4AaIC7W72vTasmf1TS\naPx8VNI3K73I3YN97Nu3r+1lYPlYvl5cvpCXzT153bgVXSiPSPpnSVeY2dNm9kFJt0saMrPHJP1O\nPAwAWGdNN9e4+3VVJr2r2c8GADSHK15TMjg42O4ipIrl624hL1/Iy9aIlvSTb2jGZt6ueQNAtzIz\neQeceAUAdABCHgACRsgDQMAIeQAIGCEPAAEj5AEgYIQ8AASMkAeAgBHyABAwQh4AAkbIA0DACHkA\nCBghDwABI+QBIGCEPAAEjJAHgIAR8gAQMEIeAAJGyANAwAh5AAgYIQ8AASPkASBghDwABIyQB4CA\nEfIAEDBCHgACRsgDQMAIeQAIGCEPAAEj5AEgYIQ8AASMkAeAgBHyABAwQh4AAkbIA0DACHkACBgh\nDwABI+QBIGCEPAAEjJAHgIAR8gAQMEIeAAJGyANAwAh5AAgYIQ8AAduY5oeb2ZOS/kfSS5JecPd3\npDk/AMBqqYa8JJc06O7nUp4PAKCC9WiusXWYBwCggrRD3iV918weMrMPpTwvAECZtJtrtrv7c2Z2\niaRZMzvl7t8rThwfH19+4eDgoAYHB1MuDgB0l7m5Oc3NzTX8fnP31pWm1ozM9kn6pbtPxcO+XvMG\ngFCYmdy97mbw1JprzOwiM3tF/PzlkoYlnUxrfgCAtdJsrhmQNG1mxfl81d2PpTg/AECZdWuuWTNj\nmmsAILGOaa4BALQfIQ8AASPkASBghDwABIyQB4CAEfIAEDBCHgACRsgDQMAIeQAIGCEPAAEj5AEg\nYIQ8AASMkAeAgBHyABAwQh4AAkbIA0DACHkACBghDwABI+QBIGCEPAAEjJAHgIAR8gAQMEIeAAJG\nyANAwAh5AAgYIQ8AASPk0XUKhYKGh3dreHi3CoVCS6ft3XaNzm7bJg0PS/Fr0pgfsG7cvS2PaNbo\nZTMzMz40tMuHhnb5zMxMXdNmZmY8mx1w6V6X7vVsdmB5erPThjXm/6tfc5eiRzbrP5yYaPn8Gl32\nC01Db4izs/6sTfLiVj4I+bAkDaZGA3JoaFc8vpjF9/rQ0K6WTCtoyEte4C75Q/2XtHx+aX1REf69\nIWnIb2znUQS6T6FQ0NTUQUnS2NhNyufzKhQKGhkZ1eLiHZKk48dHNT19uOa0qamD8bhRSdLiojQ1\ndVD5fL7mtBA0uuzVpkmq+v+XKq+zWuMRmCTfCK18iJp8R6jVLFJv7buRGm2n1YLXs7mm1Ucjjfy/\nOCroXqK5BtWU77xJA6CVgd1p7dnFabfmtvvzuZz70JB7HaHXCecVWvnFUGubIPg7AyEPd68v0HO5\n7YkCoNWB3csnGFv5xdHIUUOS8bncDmr9HYSQ70GNBnp//xtaGua9GtidIOlRQ5KjgmrbCbX+9iDk\nA9fKQK9WQ6O9NizNnndJcsRXaZuamJhgm2khQj5gaQV6vQGA3lDvuZt6a/2ZzKuo7bdQ0pCnC2WH\nK+3mdvbsmTVd6J56av+a91x66eu0uLhHi4vRcDa7RwcOHJakki5zK13sKnWdy+fzdKnrUZXWfbHb\nq7R62zl+fHTVdnbppW/UuXOrP29p6XKVbrN79x7QqVOnVnX5vO22j+nBB+fjz6c7ZytZ9MXQhhmb\nebvm3clKQ33Hjm2anPz88s6QydyipaUbJP1t/OrDyuUOrdphstk9mp4uD3R2GqSjvK+9tLrPfqVt\ntr9/v86d+5SKwS8dViYzpqWlKUlSX99f6qqr3qRNmwbYdiswM7m71f16Qr79ijvK2bO/0COPnND5\n85+TVHkHKd0ZCHR0oloVlWx2j7ZufaMWFj6k0pCXvizpX8qGP7K8jbNNryDku0S1YJc+IekrkvKq\ntPHncoe0adOrJBHo6A6N1Palo5K+Ibb5tZKGPCde26D8RJa0yaWZ5RNV0q6aJ62Abld64nWi7Kri\n8v2hdB/IZF7pudz2nt4PlPDEKzX5dVSs0Tz88AmdO/deVau5lB6qckIKvSBJk6X0ZfX1/bRn2+1p\nrulAhUJBe/ce0IkT/6GlpT+V9GZVbpb5CCed0PPKe5Stbb8/Kula9Wq7PSHfQSqH+x5FG+ppEexA\nbeV3MV29/6wc/fb379d9932hJ/Yd2uQ7xNp294G4nbHY5h5dOMLFIEBtMzMznsvtiNvmx6qcx7ra\nM5lX+sTERLuLmzrRJt8Ztm27RgsLL0l6jaSbtFLziA4zs9kneuoQE2hW9R5ppbX7W5TLXakDBz4V\n7L6VtCbPb7ymYHJyUgsLj8ZDWxS1J56U9KwymVuUy20g4IGE8vm8jh37hubn53T06NfU379fUZPn\nYUXntiTpCi0svKSRkVF+VzeWWsib2U4zO2Vmj5vZnrTm02kmJyf1yU9OSbpC0nZFJ1c/IOke5XIb\ndP/9RzQ/f5yAB5qQz+d1331fUCbzY0U1+MOKavTbJb1Gi4t3LJ+87XWpNNeY2QZJP5b0Lkk/k/RD\nSde5+49KXhNcc02hUNB73nOdlpY+G4/Zoyjgv69c7mWan59rX+FQl6hJILqieGxsjC/jDjc5OalP\nf/qzWlq6XMPaoDH9QNKva0q/q+dzZ4Pc5zqid42ZvVPSPnffGQ/fKknufnvJa4IL+eHh3Zqd3SLp\niXjMFknfVybzuO6//6sERoeLenKMaDG+41Y2m9X09DTrrcMVCgV9/vf+UF9/8Ze6KB73f5Ju7B/Q\nkV+cbmfRUtEpbfKvlfR0yfAz8bignT17RtFh4xZJz0o6JOnf9JnP3EJQdIGpqanlgJekxcXF5Vo9\nOlc+n9fHX/zVcsBL0kWSbii/HWaPSutWw3VV0cfHx5efDw4OanBwMKXirJeNik6yfkVS1K/X7ON6\n+9vf3s5CAcHLZExaqjAuAHNzc5qbm2v4/Wk111wtabykuWavpCV3v6PkNYE21zwr6SOSNks6KOlZ\n5XIbND9/vL2FwwXRXNOdqjfXbNaRXzzXzqKlolOaax6SdLmZXWZmfZLep6iTeNDGxm5SJvO4ou6S\no4qabaSFhUc1OTnZzqKhDvl8XtPT0xoaGtLQ0BAB3wWKV8R++8WLNaLdOqZLdEyXxM9f3u7idYTU\nLoYys3dL+pykDZLudvcDZdODq8lLpV0ob9BKs81JRV0of0sHDuwlOIAW2bZtUAsLH5R0l6IOfcUb\nmX1CudwVQR5Bd0TvmrpmHGjIS8UN71daabYZVbGNvtdupgSkIbov1P74osPPKtrP3i9pqySpr++U\njh79WpD7Wac01/S0Awf2xs02UtQuX/xd1s1aXNyi66+/mavxgIQKhYKGh3dr27ZrdO21fxLfNuQG\nRdejnJZ0o6QfK5d7WbAB3whq8imJLtKY0tLSFapUo+/r+3NdddVbtGnTq7jzJHABq+9GGd29deVe\nUL3VyYHmmg5SPKQ8ceLRkrAflVRQdCVs1H5I4APVFQoFXX/9zSU//r1bK+Hee02hNNd0kHw+r/n5\n47r//iPq73++ZMpBRQEfNeGcP79RCwsf1OzstdxYCT2v2CwzPLxbk5OTGhkZ1blzl5S84iZFP7pz\nWtIHlMmMKZc71BMB34i0LoZCieLNlKLDTSm6GraoNPClxcWTuv76m/W2t72FWj16xspthM/okUce\n0/nzfyNJeuCBMS0tTWml1h7p63tRV111KD765ZYhtdBcs44qb8jF9sW1zTj8xitCVfoTfzt2bNPk\n5OfL2tuLgf5Ord4/xtXf/3zP/ApUJbTJd4kLB74kfUKZzD3Ld7Uk9BGC8p/0y2SKtfXS9vbq+0Cv\nN8sQ8l2oGPgPP3yi5OSStLoWI1Xb4CUt14oIfnSa0lr72NhNmpo6qNnZ0iAvr61zNFsLId/Fatdw\npLWhf1i53F06deony+8h+NFu1Ztiou1z69at8VWqlSsv9DarLWnIc+K1g0T3TjlcsoPcosnJPSre\n/TaTeVxLZXfae+qp0/EOVDxxK+3du39V8B8/PkrwIxXltXRJqyoqKydOV7ZP6S5lsyvbdTb7Fd12\n25gefPBo/DlcyNRSSX71u5WPaNa4kJmZGR8a2uVDQ7t8YmLCs9mB+Nfp7/VsdsBzuR3xsC//cn1/\n/xvWjMvltq9578zMzKrPn5mZaffiogNU2iaqjbvw9nj1mm2x+Blsd42Js7P+rE3y4lY+CPnGlO8c\n9e1oyYK/0nwQnnqDu1LlovjeC29nY57JvLLiNobGEPI9qJXBX/yMpOHPl0LnqjfM6w/ue5c/r56K\nw8TEBNtGCxHycPfGg7/azlsr/Gt9KVQqy4XGo7qk/8skYV5t3SetDLBe00XIo6p6gj9pANQaX5xn\nK78Y0pqW5P/WrmmN/C+TrrMkzTXN/E/ROEIeiTR7KH+hkG/lF0Na06r9H9pRllYGdq33JG2SI8w7\nByGPlkgS/usVTGlNa6T8nTStmS9Mgrv7JA15+smjonw+v6avcnk//rGxlcvLq40fG7tJx4+PlvSJ\n3qOxsajPfrXx621q6uCaaw2mpg52XF/tRv6XtdZZpXWMACX5RmjlQ9Tke0arThamNa2Tmo44iY0L\nEc01CEEnnNBsR1kuNA1IGvLcuwbQ2svzacZAp+IGZQAQMH7+DwCwjJAHgIAR8gAQMEIeAAJGyANA\nwAh5AAgYIQ8AASPkASBghDwABIyQB4CAEfIAEDBCHgACRsgDQMAIeQAIGCEPAAEj5AEgYIQ8AASM\nkAeAgBHyABAwQh4AAkbIA0DACHkACBghDwABI+QBIGCEPAAELJWQN7NxM3vGzBbix8405gMAqG1j\nSp/rku509ztT+nwAQB3SbK6xFD8bAFCHNEP+Y2Z2wszuNrOLU5wPAKCKhptrzGxW0uYKk26T9CVJ\nn4mH90uaknRj+QvHx8eXnw8ODmpwcLDR4gBAkObm5jQ3N9fw+83dW1eaSjMwu0zSt9z9zWXjPe15\nA0BozEzuXndzeFq9a15dMjgi6WQa8wEA1JZW75o7zOytinrZPCHpwynNBwBQQ+rNNVVnTHMNACTW\nEc01AIDOQMgDQMAIeQAIGCEPAAEj5AEgYIQ8AASMkAeAgBHyABAwQh4AAkbIA0DACHkACBghDwAB\nI+QBIGCEPAAEjJAHgIAR8gAQMEIeAAJGyANAwAh5AAgYIQ8AASPkASBghDwABIyQB4CAEfIAEDBC\nHgACRsgDQMAIeQAIGCEPAAEj5AEgYIQ8AASMkAeAgBHyABAwQh4AAkbIA0DACHkACBghDwABI+QB\nIGCEPAAEjJAHgIAR8gAQMEIeAAJGyANAwAh5AAgYIQ8AASPkASBghDwABKzhkDezPzKzR8zsJTPb\nVjZtr5k9bmanzGy4+WICABrRTE3+pKQRSf9UOtLMrpT0PklXStop6Ytm1nNHDHNzc+0uQqpYvu4W\n8vKFvGyNaDh83f2Uuz9WYdIfSDri7i+4+5OSfiLpHY3Op1uFvqGxfN0t5OULedkakUYN+zWSnikZ\nfkbSa1OYDwDgAjbWmmhms5I2V5j0V+7+rQTz8USlAgC0hLk3l79m9o+Sxtx9Ph6+VZLc/fZ4eEbS\nPnf/Qdn7CH4AaIC7W72vrVmTT6B0hkcl3Wdmdypqprlc0r+WvyFJIQEAjWmmC+WImT0t6WpJ3zaz\n70iSuz8q6euSHpX0HUkf9WYPFwAADWm6uQYA0LnWvf96tYuozOwyM1s0s4X48cX1Llsr9NJFYmY2\nbmbPlKyzne0uU7PMbGe8fh43sz3tLk+rmdmTZvbv8fpa04zabczsHjM7Y2YnS8b1m9msmT1mZsfM\n7OJ2lrEZVZYv0X7XjouUKl5EFfuJu+fix0fXuVyt0ksXibmkO0vW2Uy7C9QMM9sg6e8VrZ8rJV1n\nZr/Z3lK1nEsajNdXCNevHFK0vkrdKmnW3d8k6YF4uFtVWr5E+926h0yNi6iC0IMXiYV0Av0diioa\nT7r7C5K+pmi9hSaYdebu35P0X2Wjr5V0OH5+WNJ717VQLVRl+aQE67DTapJb4sOPOTO7pt2FabFQ\nLxL7mJmdMLO7u/mwOPZaSU+XDIeyjkq5pO+a2UNm9qF2FyYlA+5+Jn5+RtJAOwuTkrr3u1RCPm4P\nO1nh8fs13vaspNe7e07SXyjqhvmKNMrXrAaXr5KOP+tdY1mvlfQlSVskvVXSc5Km2lrY5nX8+miB\n7fE+9m5JN5vZb7e7QGmKe/aFtl4T7Xet6ie/irsPNfCe85LOx8/nzeynivrYz7e4eE1rZPkk/UzS\n60uGXxeP62j1LquZ/YOkJFdBd6LydfR6rT766nru/lz893kzm1bURPW99paq5c6Y2WZ3P21mr5b0\n83YXqJXcfXl56tnv2t1cs9yuZGab4hNfMrPfUBTw/9mugrVI+UVi7zezPjPboioXiXWTeAcqGlF0\n0rmbPSTp8rinV5+iE+VH21ymljGzi4pHx2b2cknD6v51VslRSaPx81FJ32xjWVou6X6XSk2+FjMb\nkfR3kjYpuohqwd3fLWmHpL82sxckLUn6sLv/93qXr1nVls/dHzWz4kViLyqMi8TuMLO3KjocfkLS\nh9tcnqa4+4tm9meSCpI2SLrb3X/U5mK10oCkaTOTon3/q+5+rL1Fao6ZHVGUHZviizM/Lel2SV83\nsxslPSnpj9tXwuZUWL59kgaT7HdcDAUAAWt3cw0AIEWEPAAEjJAHgIAR8gAQMEIeAAJGyANAwAh5\nAAgYIQ8AAft/w2UPxzmF9TcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10996afd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "pi = np.pi\n",
    "a = np.eye(2)*np.array([10 , 2])\n",
    "print('Response Matrix:')\n",
    "print(a)\n",
    "theta = np.linspace(0,2*pi,100)\n",
    "circle = np.array([np.cos(theta), np.sin(theta)]).T\n",
    "res = np.dot(circle, a)\n",
    "plt.scatter(res[:,0],res[:,1])\n",
    "plt.scatter(0,0, color='k')\n",
    "plt.scatter(a[:,0],a[:,1],color='r')\n",
    "plt.axis('equal')\n",
    "u,s,v = np.linalg.svd(a)\n",
    "print('Our estimated stimuli profile');print(u[:,0].reshape(2,1))\n",
    "print('Our estimated receptive field');print(v[0,:])\n",
    "print('Our singular values');print(s)\n",
    "print('Our estimated TI response');print(np.dot(u[:,0].reshape(2,1), v[0,:].reshape(1,2))*s[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above I demonstrated this inuition where in red I show the two vectors composing my orthogonal response matrix with a non-uniform RF, and in blue I show the covariance (w/out mean subtracted) for unit vectors at the same angle as the blue with reference to the black, clearly the most covariance is to be found in the direction of the longest vector in my orthogonal matrix. The direction of my longest vector does in fact become my 1st estimated stimuli profile, and it is scaled exactly by its length.\n",
    "\n",
    "<h4>Non-uniform SP</h4>\n",
    "Now lets see what happens when our SP constrains the dimensionality of our matrix, this reflects the possible case where our unit only responds strongly to a subset of the stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit responses:\n",
      "[[ 1.          0.70710678  0.        ]\n",
      " [ 0.          0.70710678  1.        ]\n",
      " [ 0.          0.          0.        ]]\n",
      "RF:\n",
      "[ 1.  1.  1.]\n",
      "SP\n",
      "[ 1.5  1.5  0. ]\n"
     ]
    }
   ],
   "source": [
    "unit = np.zeros((3,3))\n",
    "unit[0,0] = 1\n",
    "unit[1,1] = 0.5**0.5\n",
    "unit[0,1] = 0.5**0.5\n",
    "unit[1,2] = 1\n",
    "\n",
    "print('Unit responses:')\n",
    "print(unit)\n",
    "print('RF:')\n",
    "print(np.sum(unit**2, 0))\n",
    "print('SP')\n",
    "print(np.sum(unit**2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F=0.333333333333\n",
      "TIA = 0.666666666667\n",
      "TIN = 0.5\n",
      "The singular values=\n",
      "[ 2.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "TIA = measure_TIA_array(unit)\n",
    "F = np.max([np.sum(unit**2,0)])/np.sum(unit**2)\n",
    "print('F='+str(F))\n",
    "TIN = (TIA-F)/(1-F)\n",
    "print('TIA = ' + str(TIA))\n",
    "print('TIN = '+ str(TIN))\n",
    "print('The singular values=')\n",
    "print(np.linalg.svd(unit, compute_uv=False)**2)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our original motivation for F was that it would take on the minimal value a class of matrices under study could take. In this case we are studying matrices with a particular RF and SP. For this matrix I posit for this RF and SP is the minimal possible value TIA can take on (for this dimensionality this is the lowest covariance two vectors orthogonal and one 45 degrees from both), which as you can see is .66, yet F is calculated as 0.33. \n",
    "\n",
    "We run into a problem attempting to find what F in general should be... when we know the RF, we fully determine the length of our column vectors, and the information from the SP constrains their direction. In the above case the compact SP constrains our column vectors to only point along the first two dimensions. Thus our assumption of orthogonality gives a much lower min TIA, then is actually the case.\n",
    "\n",
    "Our trick before was to find the minimal value of TIA by assuming orthogonality of our column vectors, but for some SF's this is not possible. Determining the minimal TIA for vectors that are not correlated, amounts to finding the arrangement of vectors with an RF and SP that minimizes R's covariance. \n",
    "\n",
    "One way around this is to assume we can achieve orthogonality and follow this assumption to its logical conclusion given our knowledge of the RF and SP. \n",
    "\n",
    "Lets start with the fact that $A$ and $A^T$ have the same singular values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.77037067  4.26483488  2.39404385  2.34359505  1.88812591]\n",
      "[ 4.77037067  4.26483488  2.39404385  2.34359505  1.88812591]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.normal(size=[10,5])\n",
    "u,s,v = np.linalg.svd(a);print(s)\n",
    "u,s,v = np.linalg.svd(a.T);print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keeping the fantasy of orthogonality in mind we look at $A$ and $A^T$ and know the greatest singular value will be the highest variance of the columns of either. \n",
    "\n",
    "$$F = \\frac{max(max_i(\\sum\\limits_{j=1}^m \\ R_{i,j}^2),max_j(\\sum\\limits_{i=1}^n R_{i,j}^2))}{\\sum\\limits_{i,j}^{m,n} R_{i,j}^2}$$\n",
    "\n",
    "Keep in mind this gives a potentially conservative estimate of TIA as for some RF and SP's their forced correlation could make their floor TI much higher. Lets see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.70710678  0.        ]\n",
      " [ 0.          0.70710678  1.        ]\n",
      " [ 0.          0.          0.        ]]\n",
      "F=0.5\n",
      "TIA = 0.666666666667\n",
      "TIN = 0.333333333333\n",
      "The singular values=\n",
      "[ 2.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "unit = np.zeros((3,3));unit[0,0] = 1;unit[1,1] = 0.5**0.5;unit[0,1] = 0.5**0.5;unit[1,2] = 1\n",
    "TIA = measure_TIA_array(unit)\n",
    "F = np.max([np.sum(unit**2,0),np.sum(unit**2,1)])/np.sum(unit**2)\n",
    "print('F='+str(F))\n",
    "TIN = (TIA-F)/(1-F)\n",
    "print('TIA = ' + str(TIA))\n",
    "print('TIN = '+ str(TIN))\n",
    "print('The singular values=')\n",
    "print(np.linalg.svd(unit, compute_uv=False)**2)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see our F gets closer to the true F (in this case TIA) but doesn't quite make it. Thus our current F as it is will give preference to units with sparser responses over shapes.\n",
    "Another way is to estimate F, we randomly draw from vectors with the RF and SP, then take the minimal TIA. \n",
    "One initial try might be to permute the columns, then take the mean, or min as our F."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.70710678  0.        ]\n",
      " [ 0.          0.70710678  1.        ]\n",
      " [ 0.          0.          0.        ]]\n",
      "F estimate min(TIAS) :0.569035593729\n",
      "F estimate mean(TIAS) :0.669254697106\n",
      "F estimate median(TIAS) :0.666666666667\n",
      "[[ 0.  0.  0.]\n",
      " [ 1.  1.  1.]\n",
      " [ 0.  0.  0.]]\n",
      "F estimate min(TIAS) :0.333333333333\n",
      "F estimate mean(TIAS) :0.648410681886\n",
      "F estimate median(TIAS) :0.666666666667\n"
     ]
    }
   ],
   "source": [
    "unit = np.zeros((3,3));unit[0,0] = 1;unit[1,1] = 0.5**0.5;unit[0,1] = 0.5**0.5;unit[1,2] = 1\n",
    "n_permute = 10000\n",
    "tias = []\n",
    "print(unit)\n",
    "for ind in range(n_permute):\n",
    "    tias.append(measure_TIA_array(permute_unit_array(unit)))\n",
    "print('F estimate min(TIAS) :' + str(min(tias)))\n",
    "print('F estimate mean(TIAS) :' + str(np.mean(tias)))\n",
    "print('F estimate median(TIAS) :' + str(np.median(tias)))\n",
    "unit[:,:] = 0\n",
    "unit[1,:] = 1\n",
    "print(unit)\n",
    "for ind in range(n_permute):\n",
    "    tias.append(measure_TIA_array(permute_unit_array(unit)))\n",
    "print('F estimate min(TIAS) :' + str(min(tias)))\n",
    "print('F estimate mean(TIAS) :' + str(np.mean(tias)))\n",
    "print('F estimate median(TIAS) :' + str(np.median(tias)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh! First of all our min sampled TIA, is lower than the true minimal TIA, and our mean TIA is higher but our median is actually perfect but this is an artifiact. As you can see I try the same procedure on anothe response, and get nowhere near the true F, which is in both cases because shuffling changes the dimensionality of my matrix.\n",
    "So what to do!? I'm not sure, to estimate stochastically we need to draw from matrices that satisfy the SP and RF (the simplest way would be to randomly flip signs, but this doesn't draw from all possible matrics). And to find F otherwise we need a method that finds the matrix with the same RF and SF that minimizes covariance, unfortunately the equation we must satisfy is a sum of squared entries in our matrix, so is undetermined, i.e. each entry could have been positive or negative, and still satisfy the equation.\n",
    "Well lets see how our methods limited as they are compare on real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Best possible and worst possible TI units</h4>\n",
    "Here I am making two pathological units, min_ti has 0 translation invariance, it is a fourier basis, and max_ti_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_ti_unit = np.concatenate([np.imag(np.fft.rfft(np.eye(5)))[:,1:], np.real(np.fft.rfft(np.eye(5)))[:,1:]], axis =1)\n",
    "min_ti_unit = np.concatenate([min_ti_unit, np.zeros((51,4))])\n",
    "the_nans = (np.nan*np.ones((np.shape(min_ti_unit)[0],1)))\n",
    "min_ti_unit = np.concatenate([min_ti_unit, the_nans], 1)\n",
    "max_ti_unit = np.tile(min_ti_unit[:,0],(5,1)).T\n",
    "min_ti_unit = np.expand_dims(min_ti_unit.T, 0)\n",
    "min_ti_unit = xr.DataArray(min_ti_unit, dims=['unit','x','shapes'])\n",
    "max_ti_unit = np.expand_dims(max_ti_unit.T, 0)\n",
    "max_ti_unit = xr.DataArray(max_ti_unit, dims=['unit','x','shapes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can look at the values of these pathological cells, here rows are positions, and columns 'shapes'. Note the first just has the same response over each position, and the second has an orthogonal basis function of first sines then cosines. In this case the cells only respond to the first couple shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect TI\n",
      "[[ 0.    -0.951 -0.588  0.588  0.951  0.     0.     0.     0.     0.   ]\n",
      " [ 0.    -0.951 -0.588  0.588  0.951  0.     0.     0.     0.     0.   ]\n",
      " [ 0.    -0.951 -0.588  0.588  0.951  0.     0.     0.     0.     0.   ]\n",
      " [ 0.    -0.951 -0.588  0.588  0.951  0.     0.     0.     0.     0.   ]\n",
      " [ 0.    -0.951 -0.588  0.588  0.951  0.     0.     0.     0.     0.   ]]\n",
      "Perfectly terrible TI\n",
      "[[ 0.    -0.951 -0.588  0.588  0.951  0.     0.     0.     0.     0.   ]\n",
      " [ 0.    -0.588  0.951 -0.951  0.588  0.     0.     0.     0.     0.   ]\n",
      " [ 1.     0.309 -0.809 -0.809  0.309  0.     0.     0.     0.     0.   ]\n",
      " [ 1.    -0.809  0.309  0.309 -0.809  0.     0.     0.     0.     0.   ]]\n"
     ]
    }
   ],
   "source": [
    "print('Perfect TI')\n",
    "print(np.round(max_ti_unit[0,:,:10],3).values)\n",
    "print('Perfectly terrible TI')\n",
    "print(np.round(min_ti_unit[0,:4,:10],3).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets load up the V4 cells, and concatenate them with our artificial cells at the top of the unit by position by shape stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = top_dir +'data/responses/v4_ti_resp.nc'\n",
    "v4 = xr.open_dataset(fn)['resp'].load()\n",
    "\n",
    "v4 = v4.transpose('unit', 'x', 'shapes') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the histogram of responses for the V4 cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEDCAYAAAA2k7/eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x102035dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_v4 = v4.values.ravel()\n",
    "all_v4 = all_v4[~np.isnan(all_v4)]\n",
    "_ = plt.hist(all_v4,log=True, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, seem to be the raw responses, without the mean subtracted.\n",
    "Now lets tack our pathological cells on to the V4 data set, and subtract the mean of the shapes at each position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v4 = xr.concat([min_ti_unit, max_ti_unit, v4], dim='unit')\n",
    "v4 = v4 - v4.mean('shapes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
