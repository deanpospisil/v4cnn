{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as  np\n",
    "import scipy.io as  l\n",
    "import os, sys\n",
    "top_dir = os.getcwd().split('v4cnn')[0]\n",
    "sys.path.append(top_dir + 'xarray')\n",
    "top_dir = top_dir+ 'v4cnn/'\n",
    "sys.path.append(top_dir)\n",
    "sys.path.append(top_dir + 'common')\n",
    "import xarray as xr\n",
    "import d_misc as dm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Measuring Translation Invariance</h4>\n",
    "A well accepted feature of the ventral stream is that it exhibits differing degrees of spatial invariance, it is thought this property allows for some of the invariances neccesary for object perception. Observations of this invariance find that it interacts with the receptive field of a cell. Typically one finds that the pattern of responses remains the same but the responses are scaled as one moves across the receptive field. To understand how this property develops it is important to quantify it in such a way that enables comparisons across diverse cell and stimuli types (i.e. different sized stimuli, receptive field sizes, stimuli selectivity).\n",
    "\n",
    "There are two avenues we try towards this measure:\n",
    "\n",
    "1. Measure a cells fit to a model of translation invariance with interpretable coefficients, here we use the singular value decomposition, and normalizations of this measure.\n",
    "\n",
    "2. Measure directly the similarity between responses at different positions, here we use covariance.\n",
    "\n",
    "We assume a unit has been stimulated with $m$ shapes, at $n$ positions where typically $m \\geq n$. This gives us an $m \\ x \\ n$ matrix of responses $R$.\n",
    "We model $R$ as the outer product of a receptive field $\\vec{f}$, and  stimuli response profile $\\vec{s}$. \n",
    "$$ \\hat{R} = \\vec{f} \\otimes \\vec{s} $$\n",
    "We do this by performing the singular value decomposition of $R$:\n",
    "$$ R = U \\Sigma V $$\n",
    "\n",
    "$U$ is $m \\ x \\ n$, its columns are eigenvectors of $R$, and the 1st column is the least squares estimate of $\\vec{s}$.\n",
    "\n",
    "V is $n \\ x \\ n$, its rows are eigenvectors of $R$, and the first column is a least squares estimate of $\\vec{f}$.\n",
    "\n",
    "$\\Sigma$ is an $n \\ x \\ n$ scaling matrix where $\\Sigma_{ii}=\\sigma_i$ are the sorted singular values of $R$, and $\\sigma_1$ is the smallest possible value of  $\\sqrt{ \\sum  (R - \\vec{f} \\otimes \\vec{s})^2}$\n",
    "\n",
    "Finally we take as our measure of fit to the TI model what we will call TIA:\n",
    "$$\\frac{\\sigma_1^2}{\\sum \\sigma_i^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure_TIA_array(unit):\n",
    "    s = np.linalg.svd(unit, compute_uv=False)\n",
    "    return (s[0]**2)/sum(s**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get some intuition for how this method works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Matrix:\n",
      "[[ 1.   0.7]\n",
      " [ 0.8  0. ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dean/anaconda/lib/python2.7/site-packages/matplotlib/collections.py:590: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == str('face'):\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD7CAYAAABt0P8jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAETVJREFUeJzt3X+s3XV9x/Hnu1QS5GcQUwS6EQO0xSwZLqGljnASprad\nLZggrv6xThNEM7LGZBtqZ7gx89fmEmIapTJc+CW0UCk1lGi7cDZxrq4oUKFV6mQpaLsZ6QqUpdi+\n98c93Fwu596ee77nnu85/TwfyY3f7/l+zvf79tPD637u+3zvuZGZSJLKMavuAiRJ/WXwS1JhDH5J\nKozBL0mFMfglqTAGvyQVZnbdBbwmIryvVJK6kJkxnfEDteLPzIH/uummm2qv4Xio0Tqtc9C/hqXO\nbgxU8EuSZp7BL0mFMfinqdFo1F3CMQ1DjWCdvWadvTUsdXYjuu0R9VpE5KDUIknDIiLIYX5zV5I0\n8wx+SSqMwS9JhTH4JakwBr8kFcbgl6TCGPySVBiDX5IKY/BLUmEMfkkqjMEvSYUx+CWpMAa/JBXG\n4Jekwhj8klQYg1+SCmPwS1JhKgd/RHwjIvZHxM4pxnwlIp6JiCci4pKq15Qkda8XK/5/ApZMdjAi\nlgEXZOaFwEeBr/XgmpKkLlUO/sz8HvDCFENWALe3xm4HzoiIOVWvK0nqTj96/OcCe8ftPwec14fr\nSpLa6NebuxP/Anz26bqSpAlm9+EazwNzx+2f13rsDUZGRsa2G40GjUZjJuuSpKHTbDZpNpuVzhGZ\n1RffEXE+8O3M/L02x5YBN2TmsohYBNycmYvajMte1CJJJYkIMnNiV2VKlVf8EXEPcAVwVkTsBW4C\n3gSQmesyc0tELIuIPcDLwIerXlOS1L2erPh7wRW/JE1fNyt+f3NXkgpj8EtSYQx+SSqMwS9JhTH4\nJakwBr8kFcbgl6TCGPySVBiDX5IKY/BLUmEMfkkqjMEvSYUx+CXNuMzk0UcfZcuWLXWXIvrzh1gk\nFeqFF17gzjvvZN26dRw8eJCdO3fWXZIw+CX1WGayfft21q1bx/r163nllVcA2LZtG2eccUbN1QkM\nfkk9cvDgQe6++25uueUWnnzyydcdW716NVdeeWVNlWki/xCLpEp27NjBunXruOeee3j55ZffcHzB\nggU89thjnHTSSTVUd/zzD7FI6qsXX3yR+++/nw0bNrQN/dmzZ3PnnXca+gPGFb+kyn7wgx9wxRVX\n8Oqrr77u8c9+9rN85jOfqamqMnSz4jf4JVWyceNGVq1a9YYV/8KFC3n00UeZPdu3EmeSrR5JfXPk\nyBHWrFnDNddcMxb6q1atAuCkk07ijjvuMPQHlMEvadoOHDjA8uXL+fznPw/AqaeeyoMPPshtt93G\nySefzJe//GUuuuiimqvUZPx2LGlannrqKa6++mr27NkDwLx589i0aRPz588HYM2aNXz84x+vs0Qd\ngz1+SR2b2M9fsWIFd9xxB6effvrYmMwkYlotZ1Vgj1/SjGjXzx8ZGeGBBx54XegDhv4QsNUjaUoH\nDhzgQx/6EA8//DAw2s+/6667WLFiRc2VqVsGv6RJHaufr+Fkq0dSWxs3bmThwoVjob9ixQq2b99u\n6B8HDH5JrzOdfr6Gk60eSWPs55fB4JcE2M8via0eSfbzC2PwSwWzn1+myq2eiFgC3AycAPxjZn5p\nwvEG8CDwn62HNmbm31a9rqRq7OeXq1LwR8QJwFrgj4Dngf+IiM2ZuWvC0H/JTF9N0oCwn1+2qq2e\nS4E9mflsZr4K3Atc1Wacv8MtDQj7+aoa/OcCe8ftP9d6bLwEFkfEExGxJSIurnhNSV2wn6/XVO3x\nd/Jxmj8C5mbmoYhYCmwC2n5Q98jIyNh2o9Gg0WhULE8S2M8/njSbTZrNZqVzVPpY5ohYBIxk5pLW\n/qeAoxPf4J3wnF8Af5CZv5nwuB/LLM0A+/nHtzo+lnkHcGFEnB8RJwIfBDZPKGpOtD6nNSIuZfSb\nzW/eeCpJvWY/X+1UCv7M/C1wA/Ad4GlgfWbuiojrI+L61rBrgJ0R8Tijt33+SZVrSjo2+/main+B\nSzrO2M8vSzetHj+rRzqO2M9XJ/zIBuk4YT9fnTL4pSFnP1/TZatHGmL289UNg18aUvbz1S1bPdIQ\nsp+vKgx+aYjYz1cv2OqRhoT9fPWKwS8NAfv56iVbPdKAs5+vXjP4pQFlP18zxVaPNIDs52smGfzS\ngLGfr5lmq0caIPbz1Q8GvzQA7Oern2z1SDWzn69+M/ilGtnPVx1s9Ug1sZ+vuhj8Up/Zz1fdbPVI\nfWQ/X4PA4Jf6xH6+BoWtHqkP7OdrkBj80gyyn69BZKtHmiH28zWoDH5pBtjP1yCz1SP1mP18DTqD\nX+oR+/kaFrZ6pB6wn69hYvBLFdnP17Cx1SNVYD9fw8jgl7pgP1/DzFaPNE328zXsDH5pGuzn63hQ\nudUTEUsiYndEPBMRN04y5iut409ExCVVrynVYdj6+Q899BBPP/00mVl3KRowlYI/Ik4A1gJLgIuB\nlRGxYMKYZcAFmXkh8FHga1WuKfXbsPbzDx8+zDve8Q4uuOACVq9ezbZt2zh8+HDdZWkARJXVQERc\nBtyUmUta+58EyMwvjhtzC/BIZq5v7e8GrsjM/RPOla5MNGgOHDjAtddey9atWwE45ZRTuPXWW1m2\nbFnNlR3b0aNHWbx4Mbt27Rp77LTTTuO9730vy5cvZ+nSpZx11lk1VqheiAgyM6bznKo9/nOBveP2\nnwMWdjDmPGA/0oDbsGHDWOgDvPTSS6xcubLGiqo5ePAg9913H/fddx+zZs3isssuY/ny5SxfvpwF\nCxYQMa380JCqGvydLtEnvpraPm9kZGRsu9Fo0Gg0uipK6pXrrruOT3ziExw6dKjuUnru6NGjfP/7\n32ffvn3s27ePj33sY8ybN6/usnQMzWaTZrNZ6RxVWz2LgJFxrZ5PAUcz80vjxtwCNDPz3ta+rR4N\nlbVr13Lo0KGhXA1//etfH3sz+jWzZs1i8eLFYyv9+fPnD+X/N43qptVTNfhnAz8FrgR+CfwQWJmZ\nu8aNWQbckJnLWt8obs7MRW3OZfBLPfTzn/+cefPmceTIEU477TSWLFky1tt/y1veUnd56pG+B3/r\nokuBm4ETgNsy8wsRcT1AZq5rjXntzp+XgQ9n5o/anMfgl3roc5/7HL/+9a953/vex+WXX86JJ55Y\nd0maAbUEf68Y/JI0fd0Ev5/VI0mFMfglqTAGvyQVxuCXpMIY/JJUGINfkgpj8EtSYQx+SSqMwS9J\nhTH4JakwBr8kFcbgl6TCGPySVBiDX5IKY/BLUmEMfkkqjMEvSYUx+CWpMAa/JBXG4Jekwhj8klQY\ng1+SCmPwS1JhDH5JKozBL0mFMfglqTAGvyQVxuCXpMIY/JJUGINfkgpj8EtSYQx+SSqMwS9JhZnd\n7RMj4kxgPfC7wLPAtZl5oM24Z4GDwBHg1cy8tNtrSpKqq7Li/ySwNTMvAv65td9OAo3MvMTQl6T6\nVQn+FcDtre3bgaunGBsVriNJ6qEqwT8nM/e3tvcDcyYZl8C2iNgREddVuJ4kqQem7PFHxFbg7DaH\n1ozfycyMiJzkNO/KzF9FxFuBrRGxOzO/127gyMjI2Haj0aDRaExVniQVp9ls0mw2K50jMifL62M8\nMWI3o737fRHxNuCRzJx/jOfcBLyUmf/Q5lh2W4sklSoiyMxptdOrtHo2A6ta26uATW0KenNEnNra\nPhl4D7CzwjUlSRVVWfGfCWwAfodxt3NGxDnArZn5xxHxduBbrafMBu7OzC9Mcj5X/JI0Td2s+LsO\n/l4z+CVp+vrd6pEkDSGDX5IKY/BLUmEMfkkqjMEvSYUx+CWpMAa/JBXG4Jekwhj8klQYg1+SCmPw\nS1JhDH5JKozBL0mFMfglqTAGvyQVxuCXpMIY/JJUGINfkgpj8EtSYQx+SSqMwS9JhTH4JakwBr8k\nFcbgl6TCGPySVBiDX5IKY/BLUmEMfkkqjMEvSYUx+CWpMAa/JBXG4JekwnQd/BHxgYh4KiKORMQ7\npxi3JCJ2R8QzEXFjt9eTJPVGlRX/TuD9wL9ONiAiTgDWAkuAi4GVEbGgwjUlSRXN7vaJmbkbICKm\nGnYpsCczn22NvRe4CtjV7XUlSdXMdI//XGDvuP3nWo9Jkmoy5Yo/IrYCZ7c59OnM/HYH58+uqpIk\nzZgpgz8z313x/M8Dc8ftz2V01d/WyMjI2Haj0aDRaFS8vCQdX5rNJs1ms9I5IrPaojwiHgH+MjMf\na3NsNvBT4Ergl8APgZWZ+YYef0Rk1VokqTQRQWZO+WbrRFVu53x/ROwFFgEPRcTDrcfPiYiHADLz\nt8ANwHeAp4H17UJfktQ/lVf8veKKX5Kmr68rfknScDL4JakwBr8kFcbgl6TCGPySVBiDX5IKY/BL\nUmEMfkkqjMEvSYUx+CWpMAa/JBXG4Jekwhj8klQYg1+SCmPwS1JhDH5JKozBL0mFMfglqTAGvyQV\nxuCXpMIY/NPUbDbrLuGYhqFGsM5es87eGpY6u2HwT9MwvBiGoUawzl6zzt4aljq7YfBLUmEMfkkq\nTGRm3TUAEBGDUYgkDZnMjOmMH5jglyT1h60eSSqMwS9Jhakl+CPi7yNiV0Q8ERHfiojTJxm3JCJ2\nR8QzEXFjDXV+ICKeiogjEfHOKcY9GxFPRsSPI+KH/ayxdf1O66x7Ps+MiK0R8bOI+G5EnDHJuFrm\ns5P5iYivtI4/ERGX9Ku2CTVMWWdENCLif1vz9+OI+JsaavxGROyPiJ1TjBmEuZyyzgGZy7kR8Ujr\nv/GfRMRfTDKu8/nMzL5/Ae8GZrW2vwh8sc2YE4A9wPnAm4DHgQV9rnM+cBHwCPDOKcb9Ajizjrns\ntM4Bmc+/A/66tX1ju3/3uuazk/kBlgFbWtsLgX+v4d+6kzobwOZ+1zahhsuBS4CdkxyvfS47rHMQ\n5vJs4Pdb26cAP6362qxlxZ+ZWzPzaGt3O3Bem2GXAnsy89nMfBW4F7iqXzUCZObuzPxZh8On9a56\nL3VYZ+3zCawAbm9t3w5cPcXYfs9nJ/MzVn9mbgfOiIg5/S2z43/H2l6PAJn5PeCFKYYMwlx2UifU\nP5f7MvPx1vZLwC7gnAnDpjWfg9Dj/wiwpc3j5wJ7x+0/13psECWwLSJ2RMR1dRcziUGYzzmZub+1\nvR+Y7IVZx3x2Mj/txrRbtMykTupMYHHrR/4tEXFx36rr3CDMZScGai4j4nxGf0LZPuHQtOZzdq8L\ne01EbGX0R5SJPp2Z326NWQMczsxvthnXl/tMO6mzA+/KzF9FxFuBrRGxu7WS6Jke1Fn3fK55XTGZ\nOcXvbsz4fLbR6fxMXP31+37oTq73I2BuZh6KiKXAJkZbgYOm7rnsxMDMZUScAtwPrG6t/N8wZML+\npPM5Y8Gfme+e6nhE/BmjfakrJxnyPDB33P5cRr+L9dSx6uzwHL9q/e//RMQDjP443tOg6kGdtc9n\n6020szNzX0S8DfjvSc4x4/PZRifzM3HMea3H+umYdWbmi+O2H46Ir0bEmZn5mz7V2IlBmMtjGpS5\njIg3ARuBuzJzU5sh05rPuu7qWQL8FXBVZv7fJMN2ABdGxPkRcSLwQWBzv2pso22fLyLeHBGntrZP\nBt4DTHonQx9M1o8chPncDKxqba9idPX0OjXOZyfzsxn401Zti4AD41pX/XLMOiNiTkREa/tSRn9R\nc5BCHwZjLo9pEOaydf3bgKcz8+ZJhk1vPmt6l/oZ4L+AH7e+vtp6/BzgoXHjljL6DvYe4FM11Pl+\nRvtmrwD7gIcn1gm8ndE7Kx4HfjKodQ7IfJ4JbAN+BnwXOGOQ5rPd/ADXA9ePG7O2dfwJprjTq846\ngT9vzd3jwL8Bi2qo8R7gl8Dh1mvzIwM6l1PWOSBz+YfA0VYNr2Xm0irz6Uc2SFJhBuGuHklSHxn8\nklQYg1+SCmPwS1JhDH5JKozBL0mFMfglqTAGvyQV5v8B8e0ODkK94MYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103bbb9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = np.array([[1, 0.7],[.8, 0]])\n",
    "print('Response Matrix:')\n",
    "\n",
    "print(r)\n",
    "plt.figure()\n",
    "_ = plt.quiver(0,0,r[0,:],r[1,:],angles='xy',scale_units='xy',scale=1)\n",
    "plt.axis('equal');plt.xlim(-2,2);plt.ylim(-2,2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a response matrix with shapes along rows, and position along columns. The geometric picture of this situation is shown below, where we see two orthogonal vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our estimated stimuli profile\n",
      "[[ 0.86]\n",
      " [ 0.52]]\n",
      "Our estimated receptive field\n",
      "[ 0.9   0.43]\n",
      "Our singular values\n",
      "[ 1.4  0.4]\n",
      "Our estimated TI response\n",
      "[[ 1.09  0.51]\n",
      " [ 0.65  0.31]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD7CAYAAABt0P8jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107c36e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pi = np.pi;theta = np.linspace(0,2*pi-2*pi/20.,20)\n",
    "circle = np.array([np.cos(theta), np.sin(theta)]).T\n",
    "res = np.dot(circle, r.T)\n",
    "_ = plt.quiver(0,0,r[0,:],r[1,:],angles='xy',\n",
    "               scale_units='xy',scale=1)\n",
    "u,s,v = np.linalg.svd(r)\n",
    "_ = plt.quiver(0,0, -u[0,0], -u[1,0],angles='xy',\n",
    "               scale_units='xy',scale=1, color='r')\n",
    "_ = plt.quiver(0,0, res[:,0], res[:,1], alpha=0.3,\n",
    "               angles='xy',scale_units='xy',scale=1, color='k', width=0.003)\n",
    "plt.axis('equal');plt.xlim(-2,2);plt.ylim(-2,2);\n",
    "print('Our estimated stimuli profile');print(np.round(-u[:,0].reshape(2,1),2))\n",
    "print('Our estimated receptive field');print(np.round(-v[0,:],2))\n",
    "print('Our singular values');print(np.round(s,2))\n",
    "print('Our estimated TI response');print(np.round(np.dot(u[:,0].reshape(2,1), v[0,:].reshape(1,2))*s[0],2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In black we have the columns of $R$ , in red we have our estimated stimuli profile vector, <font color='red'> $ \\vec{s}$</font>.\n",
    "\n",
    "We can get some sense for what is special about $\\vec{s}$, by looking at the grey arrows, which are the result of taking a unit vector and seeing at many different directions how much it covaried with our response vectors, as shown by their length. \n",
    "\n",
    "You can see as it comes to point somewhere in the middle of the two response vectors, covariance is maximal, and this direction is $\\vec{s}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD7CAYAAABt0P8jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBIbgB4DAEPwAEJj/B0JLMlt/Tc8gAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103bbbed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.quiver(0,0,r[0,:],r[1,:],angles='xy',\n",
    "               scale_units='xy',scale=1)\n",
    "u,s,v = np.linalg.svd(r)\n",
    "rhat = np.dot(u[:,0].reshape(2,1), v[0,:].reshape(1,2))*s[0]\n",
    "_ = plt.quiver(0,0, rhat[0,0], rhat[1,0],angles='xy',\n",
    "               scale_units='xy',scale=1, color='g', alpha=0.5)\n",
    "_ = plt.quiver(0,0, rhat[0,1], rhat[1,1],angles='xy',\n",
    "               scale_units='xy',scale=1, color='b',alpha=0.5)\n",
    "plt.axis('equal');plt.xlim(-2,2);plt.ylim(-2,2);\n",
    "plt.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our estimated receptive field,  $ \\ \\vec{f}$, scales $\\vec{s}$ to best fit each column of $R$. In blue you see the scaling of $\\vec{s}$ to match the smaller response, and in green you see its scaling for the larger response pointing to the upper-right.\n",
    "\n",
    "<h4>Negative receptive field profiles</h4>\n",
    "One final issue that should be taken into account is responses that are negatively correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Matrix:\n",
      "[[ 1.  -0.7]\n",
      " [ 0.8  0. ]]\n",
      "Our estimated stimuli profile\n",
      "[[ 0.85707503]\n",
      " [ 0.5151916 ]]\n",
      "Our estimated receptive field\n",
      "[ 0.90408501 -0.42735265]\n",
      "Our singular values\n",
      "[ 1.4038816   0.39889404]\n",
      "Our estimated TI response\n",
      "[[ 1.0878239  -0.51420433]\n",
      " [ 0.65389577 -0.3090905 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD7CAYAAABt0P8jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103bbbd10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = np.array([[1, -0.7],[.8, 0]])\n",
    "print('Response Matrix:');print(r)\n",
    "_ = plt.quiver(0,0,r[0,:],r[1,:],angles='xy',\n",
    "               scale_units='xy',scale=1)\n",
    "u,s,v = np.linalg.svd(r)\n",
    "rhat = np.dot(u[:,0].reshape(2,1), v[0,:].reshape(1,2))*s[0]\n",
    "_ = plt.quiver(0,0, rhat[0,0], rhat[1,0],angles='xy',\n",
    "               scale_units='xy',scale=1, color='g', alpha=0.5)\n",
    "_ = plt.quiver(0,0, rhat[0,1], rhat[1,1],angles='xy',\n",
    "               scale_units='xy',scale=1, color='b',alpha=0.5)\n",
    "plt.axis('equal');plt.xlim(-2,2);plt.ylim(-2,2);\n",
    "plt.plot()\n",
    "print('Our estimated stimuli profile');print(-u[:,0].reshape(2,1))\n",
    "print('Our estimated receptive field');print(-v[0,:])\n",
    "print('Our singular values');print(s)\n",
    "print('Our estimated TI response');print(np.dot(u[:,0].reshape(2,1), v[0,:].reshape(1,2))*s[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though our two responses are actually anti-correlated SVD simply makes a portion of our receptive field negative to capture that variance. Intuitively this seems wrong as a cell that has the opposite response to stimuli at one position is not maintaining an invariant representation of those stimuli. \n",
    "\n",
    "One way to correct for this is to restrict our SVD to the subset of $R$'s columns with the highest non-negative covariance $R_+$. We will of course include the error resulting from those responses outside of this subset $R_-$.\n",
    "$$ \\sqrt{ \\sum (R_+ - \\vec{f}_+ \\otimes \\vec{s}_+)^2} + \\sum (R_-)^2$$ \n",
    "\n",
    "Finding this subset for large n may be non trivial as the number of possible subset is $2^n$. Albeit in a typical electrophysiological experiment n will be small.\n",
    "\n",
    "<h4>To mean substract or not?</h4>\n",
    "The entries of $R$ for a neurons responses are non-negative, thus for the raw data all of our vectors covariance will be non-negative. \n",
    "Except for some scaling of the identity matrix, the columns of positive matrices get pushed closer to each other around the direction of the mean vector $\\vec{\\mu}_i = \\frac{1}{\\sqrt{m}}$. \n",
    "\n",
    "For a positive distribution the variance is bounded by the mean and $\\vec{s}$ thus has a tendency towards $\\vec{\\mu} $ trivially inflating our TIA metric. We are interested whether a pattern of responses was maintained not the magnitude of $\\frac{\\mu}{\\sigma^2}$ for our columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>TI irrelevant dependencies of TIA</h3>\n",
    "Unfortunately as we will see TIA is dependent on factors the are irrelevant to TI such as number of positions or stimuli, receptive field size, and stimuli selectivity. Below we will try our best to deal with these issues.\n",
    "<h4>TIA depends on the number of positions measured.</h4>\n",
    "For example if we take a response that has no translation invariance, i.e. each column is orthogonal TIA will not give it a score of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  0.  0.  0.  0.]\n",
      " [ 0.  2.  0.  0.  0.]\n",
      " [ 0.  0.  2.  0.  0.]\n",
      " [ 0.  0.  0.  2.  0.]\n",
      " [ 0.  0.  0.  0.  2.]]\n",
      "TIA = 0.2\n"
     ]
    }
   ],
   "source": [
    "unit = np.eye(5)*2\n",
    "print(unit)\n",
    "print('TIA = ' + str(measure_TIA_array(unit)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It instead gives TIA of 0.2, why is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The singular values of our unit:\n",
      "[ 2.  2.  2.  2.  2.]\n"
     ]
    }
   ],
   "source": [
    "print('The singular values of our unit:')\n",
    "print(np.linalg.svd(unit, compute_uv=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the SVD guarantees only that $$\\sigma_1 \\ge \\dots \\ge \\sigma_n$$ and in the above case $$\\sigma_1 = \\dots = \\sigma_n$$ thus $$\\frac{\\sigma_1^2}{\\sum \\sigma_i^2} = \\frac{1}{n}$$ where $n$ is the number of positions. This is uniquely the case where all columns of our matrix have equal length and are orthogonal.\n",
    "In this case $TIA>=\\frac{1}{n}$ thus TIA depends on the number of positions measured which is irrelevant to TI.\n",
    "\n",
    "To correct for this in general we can try to figure out, for the type of matrices we are dealing with, what $F$ is where $TIA>=F$\n",
    "\n",
    "Then we get a normalized value $$TIN = \\frac{TIA-F}{(1-F)}$$\n",
    "\n",
    "If for example we take $F = \\frac{1}{n}$ we are guranteed that TIN over all possible response matrices will range between 0, and 1. Lets check for our previous matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIA = 0.2\n",
      "TIN = 0.0\n"
     ]
    }
   ],
   "source": [
    "unit = np.eye(5)\n",
    "TIA = measure_TIA_array(unit)\n",
    "F = 1./len(unit[:,])\n",
    "TIN = (TIA-F)/((1-F))\n",
    "print('TIA = ' + str(TIA))\n",
    "print('TIN = '+ str(TIN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! \n",
    "Our ideal goal for TIN will be to make a comparison between response matrices of different RF and SP, such that a particular RF or SP doesn't advantage one cell over another, and when making a comparison we can assign some confidence to the amount of TI that resulted from trial to trial variation, and that deriving from the expected value of the response. \n",
    "\n",
    "Ideally we would know the distribution of TIA for IID noise under the constraint of a RF and SP, then assign some confidence to the likelihood of a difference in TI between two cells of differing RF and SP.\n",
    "\n",
    "For now we will potentially incorrectly assume that the distribution of TIA for IID noise with some RF and SP  are simple rescalings of each other, thus scaling our distribution between F and 1 equates the two distributions of TIN.\n",
    "In reality our distribution is probably more akin to an F-distribution.\n",
    "In other words given an RF and SF we want the F that is the minimal possible TI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Non-Uniform RF</h4>\n",
    "\n",
    "While $F = \\frac{1}{n}$ works in the previous case lets look at the case where we know our matrix does not have column vectors of equal length i.e. a non-uniform RF. Here we are essentially trying to remove receptive field size as a factor in TI i.e. just because two cells have different RF sizes, doesn't mean one should get better TI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit responses:\n",
      "[[ 0.  1.  1.  0.]\n",
      " [ 0.  1. -1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1. -1.  0.]]\n",
      "RF:\n",
      "[ 0.  4.  4.  0.]\n"
     ]
    }
   ],
   "source": [
    "unit = np.zeros((4,4))\n",
    "unit[:,1] = 1\n",
    "unit[:,2] = [1,-1,1,-1]\n",
    "\n",
    "print('Unit responses:')\n",
    "print(unit)\n",
    "print('RF:')\n",
    "print(np.sum(unit**2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the cell has a non-uniform RF.\n",
    "\n",
    "Keep in mind again the columns are orthogonal so intuitively we should expect a translation invariance of 0.\n",
    "\n",
    "What is our measure of TIA and TIN where $F = \\frac{1}{n}$, for this response matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F=0.25\n",
      "TIA = 0.5\n",
      "TIN = 0.333333333333\n",
      "The singular values=\n",
      "[ 2.  2.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "TIA = measure_TIA_array(unit)\n",
    "F = 1./len(unit[:,])\n",
    "print('F=' + str(F))\n",
    "TIN = (TIA-F)/(1-F)\n",
    "print('TIA = ' + str(TIA))\n",
    "print('TIN = '+ str(TIN))\n",
    "print('The singular values=')\n",
    "print(np.linalg.svd(unit, compute_uv=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terrible! It seems a non-translation invariant cell can take on translation invariance simply with a non-uniform receptive field, in this case a compact receptive field. \n",
    "\n",
    "Even if our columns are orthogonal $\\sigma_1$ will simply equal the magnitude of the greatest response position, or the center of the RF.\n",
    "\n",
    "In the case of all response matrices with non-uniform RF's what F do we need?\n",
    "$$F = \\frac{max_i(\\sum\\limits_{j=1}^m R_{i,j}^2)}{\\sum\\limits_{i,j}^{m,n} R_{i,j}^2}$$\n",
    "\n",
    "The variance of the position with the greatest variance divided by the total variance. \n",
    "\n",
    "Lets see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  1.  0.]\n",
      " [ 0.  1. -1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1. -1.  0.]]\n",
      "F= 0.5\n",
      "TIA = 0.5\n",
      "TIN = 2.22044604925e-16\n"
     ]
    }
   ],
   "source": [
    "print(unit)\n",
    "TIA = measure_TIA_array(unit)\n",
    "F = max(np.sum(unit**2,0))/np.sum(unit**2)\n",
    "TIN = (TIA-F)/(1-F)\n",
    "print('F= ' +str(F))\n",
    "print('TIA = ' + str(TIA))\n",
    "print('TIN = '+ str(TIN))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! The intuition behind this correction is that if we only know the length of each column vector, the direction of those vectors is still free to vary. With direction freely varying but length fixed vectors, what is the minimal singular value they could take on? It is the case where all columns are orthogonal to each other, and in this case the principal component will take on the direction of the longest vector, and will account for only its variance (because all other columns are orthogonal to it).\n",
    "Now lets try to add on one more constraint the SR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above I demonstrated this inuition where in red I show the two vectors composing my orthogonal response matrix with a non-uniform RF, and in blue I show the covariance (w/out mean subtracted) for unit vectors at the same angle as the blue with reference to the black, clearly the most covariance is to be found in the direction of the longest vector in my orthogonal matrix. The direction of my longest vector does in fact become my 1st estimated stimuli profile, and it is scaled exactly by its length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Non-uniform SP</h4>\n",
    "Now lets see what happens when our SP constrains the dimensionality of our matrix, this reflects the possible case where our unit only responds strongly to a subset of the stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit responses:\n",
      "[[ 1.          0.70710678  0.        ]\n",
      " [ 0.          0.70710678  1.        ]\n",
      " [ 0.          0.          0.        ]]\n",
      "RF:\n",
      "[ 1.  1.  1.]\n",
      "SP\n",
      "[ 1.5  1.5  0. ]\n"
     ]
    }
   ],
   "source": [
    "unit = np.zeros((3,3))\n",
    "unit[0,0] = 1;unit[1,1] = 0.5**0.5;unit[0,1] = 0.5**0.5;unit[1,2] = 1\n",
    "\n",
    "print('Unit responses:')\n",
    "print(unit)\n",
    "print('RF:')\n",
    "print(np.sum(unit**2, 0))\n",
    "print('SP')\n",
    "print(np.sum(unit**2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F=0.333333333333\n",
      "TIA = 0.666666666667\n",
      "TIN = 0.5\n",
      "The singular values=\n",
      "[ 2.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "TIA = measure_TIA_array(unit)\n",
    "F = np.max([np.sum(unit**2,0)])/np.sum(unit**2)\n",
    "print('F='+str(F))\n",
    "TIN = (TIA-F)/(1-F)\n",
    "print('TIA = ' + str(TIA))\n",
    "print('TIN = '+ str(TIN))\n",
    "print('The singular values=')\n",
    "print(np.linalg.svd(unit, compute_uv=False)**2)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our original motivation for F was that it would take on the minimal value a class of matrices under study could take. In this case we are studying matrices with a particular RF and SP. For this matrix I posit for this RF and SP is the minimal possible value TIA can take on (for this dimensionality this is the lowest covariance two vectors orthogonal and one 45 degrees from both), which as you can see is .66, yet F is calculated as 0.33. \n",
    "\n",
    "We run into a problem attempting to find what F in general should be... when we know the RF, we fully determine the length of our column vectors, and the information from the SP constrains their direction. In the above case the compact SP constrains our column vectors to only point along the first two dimensions. Thus our assumption of orthogonality gives a much lower min TIA, then is actually the case.\n",
    "\n",
    "Our trick before was to find the minimal value of TIA by assuming orthogonality of our column vectors, but for some SF's this is not possible. Determining the minimal TIA for vectors that are not correlated, amounts to finding the arrangement of vectors with an RF and SP that minimizes R's covariance. \n",
    "\n",
    "One way around this is to assume we can achieve orthogonality and follow this assumption to its logical conclusion given our knowledge of the RF and SP. \n",
    "\n",
    "Lets start with the fact that $A$ and $A^T$ have the same singular values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.8941688   3.83006661  2.2749054   1.96671381  1.23424692]\n",
      "[ 4.8941688   3.83006661  2.2749054   1.96671381  1.23424692]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.normal(size=[10,5])\n",
    "u,s,v = np.linalg.svd(a);print(s)\n",
    "u,s,v = np.linalg.svd(a.T);print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keeping the fantasy of orthogonality in mind we look at $A$ and $A^T$ and know the greatest singular value will be the highest variance of the columns of either. \n",
    "\n",
    "$$F = \\frac{max(max_i(\\sum\\limits_{j=1}^m \\ R_{i,j}^2),max_j(\\sum\\limits_{i=1}^n R_{i,j}^2))}{\\sum\\limits_{i,j}^{m,n} R_{i,j}^2}$$\n",
    "\n",
    "Keep in mind this gives a potentially conservative estimate of TIA as for some RF and SP's their forced correlation could make their floor TI much higher. Lets see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.70710678  0.        ]\n",
      " [ 0.          0.70710678  1.        ]\n",
      " [ 0.          0.          0.        ]]\n",
      "F=0.5\n",
      "TIA = 0.666666666667\n",
      "TIN = 0.333333333333\n",
      "The singular values=\n",
      "[ 2.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "unit = np.zeros((3,3));unit[0,0] = 1;unit[1,1] = 0.5**0.5;unit[0,1] = 0.5**0.5;unit[1,2] = 1\n",
    "TIA = measure_TIA_array(unit)\n",
    "F = np.max([np.sum(unit**2,0),np.sum(unit**2,1)])/np.sum(unit**2)\n",
    "print(unit)\n",
    "print('F='+str(F))\n",
    "TIN = (TIA-F)/(1-F)\n",
    "print('TIA = ' + str(TIA))\n",
    "print('TIN = '+ str(TIN))\n",
    "print('The singular values=')\n",
    "print(np.linalg.svd(unit, compute_uv=False)**2)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see our F gets closer to the true F (in this case TIA) but doesn't quite make it. Thus our current F as it is will give preference to units with sparser responses over shapes.\n",
    "Another way is to estimate F, we randomly draw from vectors with the RF and SP, then take the minimal TIA. \n",
    "One initial try might be to permute the columns, then take the mean, or min as our F."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.70710678  0.        ]\n",
      " [ 0.          0.70710678  1.        ]\n",
      " [ 0.          0.          0.        ]]\n",
      "F estimate min(TIAS) :0.569035593729\n",
      "F estimate mean(TIAS) :0.674181770322\n",
      "F estimate median(TIAS) :0.666666666667\n",
      "[[ 0.  0.  0.]\n",
      " [ 1.  1.  1.]\n",
      " [ 0.  0.  0.]]\n",
      "F estimate min(TIAS) :0.333333333333\n",
      "F estimate mean(TIAS) :0.646924218494\n",
      "F estimate median(TIAS) :0.666666666667\n"
     ]
    }
   ],
   "source": [
    "def permute_unit(unit):\n",
    "    unit = unit.dropna('x', 'all').dropna('shapes', 'all')\n",
    "    for x in range(len(unit.coords['x'])):\n",
    "        unit[x,:] = np.random.permutation(unit[x,:].values)\n",
    "    return unit \n",
    "def permute_unit_array(unit):\n",
    "    for x in range(np.shape(unit)[1]):\n",
    "        unit[:,x] = np.random.permutation(unit[:,x])\n",
    "    return unit\n",
    "\n",
    "unit = np.zeros((3,3));unit[0,0] = 1;unit[1,1] = 0.5**0.5;unit[0,1] = 0.5**0.5;unit[1,2] = 1\n",
    "n_permute = 1000\n",
    "tias = []\n",
    "print(unit)\n",
    "for ind in range(n_permute):\n",
    "    tias.append(measure_TIA_array(permute_unit_array(unit)))\n",
    "print('F estimate min(TIAS) :' + str(min(tias)))\n",
    "print('F estimate mean(TIAS) :' + str(np.mean(tias)))\n",
    "print('F estimate median(TIAS) :' + str(np.median(tias)))\n",
    "unit[:,:] = 0\n",
    "unit[1,:] = 1\n",
    "print(unit)\n",
    "for ind in range(n_permute):\n",
    "    tias.append(measure_TIA_array(permute_unit_array(unit)))\n",
    "print('F estimate min(TIAS) :' + str(min(tias)))\n",
    "print('F estimate mean(TIAS) :' + str(np.mean(tias)))\n",
    "print('F estimate median(TIAS) :' + str(np.median(tias)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh! First of all our min sampled TIA, is lower than the true minimal TIA, and our mean TIA is higher but our median is actually perfect but this is an artifiact. As you can see I try the same procedure on anothe response, and get nowhere near the true F, which is in both cases because shuffling changes the dimensionality of my matrix.\n",
    "So what to do!? I'm not sure, to estimate stochastically we need to draw from matrices that satisfy the SP and RF (the simplest way would be to randomly flip signs, but this doesn't draw from all possible matrics). And to find F otherwise we need a method that finds the matrix with the same RF and SF that minimizes covariance, unfortunately the equation we must satisfy is a sum of squared entries in our matrix, so is undetermined, i.e. each entry could have been positive or negative, and still satisfy the equation.\n",
    "\n",
    "<h4>Alternative measures of TI</h4>\n",
    "Another option is to give up on an explicitly fit model of TI:\n",
    "$$ R = \\vec{f} \\otimes \\vec{s} $$\n",
    "We are in the end trying to measure covariance of responses by position, in our TIA measure we evaluated this by finding how well we could explain all of our variance with a single vector, another way we could go about it is by finding the total covariance and scaling it by the total possible covariance. \n",
    "\n",
    "$$\\frac{\\sum\\limits_{i,j \\in i \\neq j} \\vec{x}_{i} \\vec{x}_{j}^T }{\\sum\\limits_{i,j \\in i \\neq j} || \\vec{x}_{i} || \\ || \\vec{x}_{j} ||}$$\n",
    "\n",
    "This will have a couple nice properties, if the columns are orthogonal then it will give us zero. Thus it solves all our problems up to Non-Uniform RF, but in the cases where the direction of our column vectors becomes constrained it does not easily provide a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  1.  0.]\n",
      " [ 0.  1. -1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1. -1.  0.]]\n",
      "total covariance: 0.0\n",
      "total possible covariance: 4.0\n",
      "normalized average covariance: 0.0\n",
      "[[ 0.  1.  4.  0.]\n",
      " [ 0.  1.  4.  0.]\n",
      " [ 0.  1.  4.  0.]\n",
      " [ 0.  1.  4.  0.]]\n",
      "total covariance: 16.0\n",
      "total possible covariance: 16.0\n",
      "normalized average covariance: 1.0\n",
      "[[ 1.          0.70710678  0.          0.        ]\n",
      " [ 0.          0.70710678  1.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "total covariance: 1.41421356237\n",
      "total possible covariance: 3.0\n",
      "normalized average covariance: 0.471404520791\n"
     ]
    }
   ],
   "source": [
    "def norm_av_cov(unit, return_num_den=False):\n",
    "    cov = np.dot(unit.T, unit)\n",
    "    cov[np.diag_indices_from(cov)] = 0\n",
    "    numerator = np.sum(np.triu(cov))\n",
    "    vlength = np.linalg.norm(unit, axis=0)\n",
    "    max_cov = np.outer(vlength.T, vlength)\n",
    "    max_cov[np.diag_indices_from(max_cov)] = 0\n",
    "    denominator= np.sum(np.triu(max_cov))\n",
    "    if return_num_den:\n",
    "        return numerator, denominator\n",
    "    else:\n",
    "        return numerator/denominator\n",
    "units = []\n",
    "unit = np.zeros((4,4));unit[:,1] = 1;unit[:,2] = [1,-1,1,-1]  \n",
    "units.append(unit) \n",
    "unit = np.zeros((4,4));unit[:,1] = 1;unit[:,2] = 4\n",
    "units.append(unit) \n",
    "unit = np.zeros((4,4));unit[0,0] = 1;unit[1,1] = 0.5**0.5;unit[0,1] = 0.5**0.5;unit[1,2] = 1\n",
    "units.append(unit) \n",
    "\n",
    "for unit in units:\n",
    "    numerator, denominator = norm_av_cov(unit, return_num_den=True)\n",
    "    print(unit)\n",
    "    print('total covariance: ' + str(numerator))\n",
    "    print('total possible covariance: ' + str(denominator))\n",
    "    print('normalized average covariance: ' + str(numerator/denominator))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first case we can see it avoids the problem of receptive field size. In the second case we see the method works to detect perfect translation invariance, but in the third case we see it does not avoid the problem of taking into account stimuli profiles where covariance is unavoidable.\n",
    "\n",
    "<h4>Geometric interpretation of the core issue with disentangling TI and SP</h4>\n",
    "Our fundamental problem is we are unable to confidently disentangle whether something is more TI because the cell is more invariant, or because only a small subset of the stimuli we chose drove the stimuli well. In geometric terms, when there is a non-uniform SP the direction of our responses is not homoschedastic, i.e. some entries of our columns have higher variance than others, and thus they are heteroschedastic favoring some directions over others. When some directions are apriori favored over others they will tend to be more correlated then their homoscedastic counterparts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'measure_TIA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a44203be6397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_scale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_tia_over_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mav_cov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnorm_av_cov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0munit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-a44203be6397>\u001b[0m in \u001b[0;36mcalc_tia_over_units\u001b[0;34m(units)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_tia_over_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mda_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shapes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmeasure_TIA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0munit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mda_units\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'measure_TIA' is not defined"
     ]
    }
   ],
   "source": [
    "def calc_tia_over_units(units):\n",
    "    da_units = xr.DataArray(units, dims=['unit', 'shapes', 'x'])\n",
    "    return np.array([measure_TIA(unit) for unit in da_units])\n",
    "    \n",
    "\n",
    "top_scale = [0.1,2.,4]\n",
    "for scale in top_scale:\n",
    "    units = np.random.normal(size=(100, 10, 5))*np.linspace(.1,scale,10).reshape((1,10,1))\n",
    "    tia = calc_tia_over_units(units)\n",
    "    av_cov = np.mean([norm_av_cov(unit) for unit in units])\n",
    "    plt.figure()\n",
    "    plt.subplot(121);plt.imshow(units[1,...], interpolation='nearest');\n",
    "    plt.title('homoscedastic sample')\n",
    "    plt.subplot(122);plt.plot((np.var(units,(0,2))**0.5), range(10));plt.ylim(9, 0);plt.xlim(0,10)\n",
    "    plt.ylabel('Shape');plt.xlabel('SD');plt.title('Mean tia: '+ str(np.round(np.mean(tia),3))\n",
    "                                              + ' Mean av_cov: ' + str(np.round(av_cov,5)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it would seem mean av_cov is not influenced by heteroscedascity like TIA, and the reason is because this heteroscedascity is symmetric! IF we can assume for a given RF and SF that it is heteroschedastically symmetric then av_cov will on average not give an advantage to any particular profile.\n",
    "\n",
    "<h4>Best possible and worst possible TI units</h4>\n",
    "Here I am making two artificial units, min_ti has 0 translation invariance, it is a fourier basis, and max_ti_unit that is just the same response over position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "min_ti_unit = np.concatenate([np.imag(np.fft.rfft(np.eye(5)))[:,1:], np.real(np.fft.rfft(np.eye(5)))[:,1:]], axis =1)\n",
    "min_ti_unit = np.concatenate([min_ti_unit, np.zeros((51,4))])\n",
    "the_nans = (np.nan*np.ones((np.shape(min_ti_unit)[0],1)))\n",
    "min_ti_unit = np.concatenate([min_ti_unit, the_nans], 1)\n",
    "max_ti_unit = np.tile(min_ti_unit[:,0],(5,1)).T\n",
    "min_ti_unit = np.expand_dims(min_ti_unit.T, 0)\n",
    "min_ti_unit = xr.DataArray(min_ti_unit, dims=['unit','x','shapes'])\n",
    "max_ti_unit = np.expand_dims(max_ti_unit.T, 0)\n",
    "max_ti_unit = xr.DataArray(max_ti_unit, dims=['unit','x','shapes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can look at the values of these pathological cells, here rows are positions, and columns 'shapes'. Note the first just has the same response over each position, and the second has an orthogonal basis function of first sines then cosines. In this case the cells only respond to the first couple shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Perfect TI')\n",
    "print(np.round(max_ti_unit[0,:,:10],3).values)\n",
    "print('Perfectly terrible TI')\n",
    "print(np.round(min_ti_unit[0,:4,:10],3).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets load up the V4 cells, and concatenate them with our artificial cells at the top of the unit by position by shape stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fn = top_dir +'data/responses/v4_ti_resp.nc'\n",
    "v4 = xr.open_dataset(fn)['resp'].load()\n",
    "\n",
    "v4 = v4.transpose('unit', 'x', 'shapes') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the histogram of responses for the V4 cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_v4 = v4.values.ravel()\n",
    "all_v4 = all_v4[~np.isnan(all_v4)]\n",
    "_ = plt.hist(all_v4,log=True, bins=100);plt.xlabel('Firing Rate');plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, seem to be the raw responses, without the mean subtracted.\n",
    "Now lets tack our pathological cells on to the V4 data set, and subtract the mean of the shapes at each position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v4 = xr.concat([min_ti_unit, max_ti_unit, v4], dim='unit')\n",
    "v4 = v4 - v4.mean('shapes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure_TIA(unit, return_uv=False):\n",
    "    unit = unit.dropna('x', 'all').dropna('shapes', 'all')\n",
    "    unit = unit.transpose('shapes','x')\n",
    "    if return_uv:\n",
    "        u,s,v = np.linalg.svd(unit.values, compute_uv=True)\n",
    "        return (s[0]**2)/np.sum(s**2), u , s,  v\n",
    "    else:\n",
    "        s = np.linalg.svd(unit.values, compute_uv=False)\n",
    "        return (s[0]**2)/np.sum(s**2)\n",
    "    \n",
    "def norm_av_cov(unit, return_num_den=False):\n",
    "    unit = unit.transpose('shapes','x')\n",
    "    unit = unit.dropna('x', 'all').dropna('shapes', 'all').values\n",
    "    cov = np.dot(unit.T, unit)\n",
    "    cov[np.diag_indices_from(cov)] = 0\n",
    "    numerator = np.sum(np.triu(cov))\n",
    "    vlength = np.linalg.norm(unit, axis=0)\n",
    "    max_cov = np.outer(vlength.T, vlength)\n",
    "    max_cov[np.diag_indices_from(max_cov)] = 0\n",
    "    denominator= np.sum(np.triu(max_cov))\n",
    "    if return_num_den:\n",
    "        return numerator, denominator\n",
    "    else:\n",
    "        return numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "av_cov = np.array([norm_av_cov(unit) for unit in v4])\n",
    "#f = 0\n",
    "tia = np.array([measure_TIA(unit) for unit in v4])\n",
    "#f = 1/n_x\n",
    "n_x = np.array([cell.dropna('x', 'all').dropna('shapes', 'all').shape[0] for cell in v4])\n",
    "f = 1./n_x\n",
    "tin_f_nx = (tia-f)/(1-f)\n",
    "#f = max(rf)/tot_var\n",
    "max_rf_var = (v4.dropna('x', 'all')**2).sum('shapes').max('x')\n",
    "tot_var = (v4**2).sum(['shapes','x'])\n",
    "f = (max_rf_var/tot_var).values\n",
    "tin_f_maxrf = (tia-f)/(1-f)\n",
    "#f = max(max(rf), max(sf))\n",
    "max_rf_var = (v4.dropna('x', 'all')**2).sum('shapes').max('x')\n",
    "max_srf_var = (v4.dropna('shapes', 'all')**2).sum('x').max('shapes')\n",
    "max_both = xr.concat([max_rf_var,max_srf_var], dim='c').max('c')\n",
    "f = max_both/tot_var\n",
    "tin_f_max_rf_srf = ((tia-f)/(1-f)).values\n",
    "#f = mean(TI(cell resp permuted))\n",
    "n_perms = 20\n",
    "tias_mean = [] \n",
    "tias_min = [] \n",
    "for unit in v4:\n",
    "     unit = unit.dropna('x', 'all').dropna('shapes', 'all')\n",
    "     all_perm_tia = [measure_TIA(permute_unit(unit)) for ind in range(n_perms)]\n",
    "     tias_mean.append(np.mean(all_perm_tia))\n",
    "     tias_min.append(np.min(all_perm_tia))\n",
    "\n",
    "f = np.array(tias_mean)\n",
    "tin_f_tias_mean = (tia-f)/(1-f)\n",
    "\n",
    "f = np.array(tias_min)\n",
    "tin_f_tias_min = (tia-f)/(1-f)\n",
    "\n",
    "tins_lst = np.array([av_cov, tia, tin_f_nx, tin_f_maxrf, tin_f_max_rf_srf, tin_f_tias_min, tin_f_tias_mean]).T\n",
    "tins_nm = ['av_cov', 'tia', 'nx', 'maxrf', 'max_rf&srf', 'tias_min', 'tias_mean']\n",
    "tins = pd.DataFrame(tins_lst, columns=tins_nm)\n",
    "\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "axes = scatter_matrix(tins[2:], alpha=1, figsize=(12, 12),s=5, color='r')\n",
    "for i, axes1 in enumerate(axes):\n",
    "    for j, ax in enumerate(axes1):\n",
    "        if i!=j:\n",
    "            ax.plot([-1,1],[-1,1], alpha=0.6, color='k');\n",
    "            ax.plot([-1,1],[0,0],alpha=0.6, color='k');\n",
    "            ax.plot([0,0], [-1,1],alpha=0.6, color='k');\n",
    "\n",
    "            ax.set_xlim(-0.2,1.1);ax.set_ylim(-0.2,1.1);\n",
    "            ax.scatter(tins.loc[:1].values[:,j],tins.loc[0:1].values[:,i], color=['b','g'], s=5)\n",
    "        else:\n",
    "            ax.set_xlim(-0.2,1.1);            \n",
    "_ = plt.tight_layout()\n",
    "_=plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a glance it would seem F=1/n doesn't do much, max rf does about the same as anyting else, except dividing max rf and sf seems to change the value of one of our cells a little bit. \n",
    "One problem we quickly note is that using TIAs mean does give us a negative value for our perfectly translation invariant unit.\n",
    "Now our worse fear is that our TI is mainly being driven by units that are sparse over shape. Let look at real units and see if we can find at least a correlation to support this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def kurtosis(da):\n",
    "    da = da.dropna('shapes')\n",
    "    da = da.transpose('shapes','unit')\n",
    "    mu = da.mean('shapes')\n",
    "    sig = da.reduce(np.nanvar, dim='shapes')\n",
    "    k = (((da - mu)**4).sum('shapes',skipna=True)/da.shapes.shape[0])/(sig**2)\n",
    "    return k\n",
    "#lets find kurtosis of our SP\n",
    "fn = top_dir +'data/responses/v4_ti_resp.nc'\n",
    "v4 = xr.open_dataset(fn)['resp'].load()\n",
    "v4 = v4.transpose('unit', 'x', 'shapes') \n",
    "v4 = v4 - v4.mean('shapes')\n",
    "sp = v4.var('x')\n",
    "k = kurtosis(sp)\n",
    "\n",
    "#f = 0\n",
    "tia = np.array([measure_TIA(unit) for unit in v4])\n",
    "max_rf_var = (v4.dropna('x', 'all')**2).sum('shapes').max('x')\n",
    "tot_var = (v4**2).sum(['shapes','x'])\n",
    "f = (max_rf_var/tot_var).values\n",
    "tin_f_maxrf = (tia-f)/(1-f)\n",
    "print(sp.shape)\n",
    "print(tin_f_maxrf.shape)\n",
    "plt.scatter(k, tia);plt.ylim(0,1);plt.ylabel('tia');plt.xlabel('k');\n",
    "print('r = ' +  str(np.corrcoef([k,tia])[0,1]))\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(k, tin_f_maxrf);plt.ylim(0,1);plt.ylabel('tin f=max_rf_var');plt.xlabel('k');\n",
    "print('r = ' +  str(np.corrcoef([k,tin_f_maxrf])[0,1]))\n",
    "\n",
    "av_cov = np.array([norm_av_cov(unit) for unit in v4])\n",
    "plt.figure()\n",
    "plt.scatter(k, tin_f_maxrf);plt.ylim(0,1);plt.ylabel('tin f=max_rf_var');plt.xlabel('k');\n",
    "print('r = ' +  str(np.corrcoef([k, av_cov])[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some correlation which either means sparser units tend to be more TI, or sparser units are biased to have a higher TIN.\n",
    "\n",
    "Lets look at the individual plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ti_in in np.argsort(tin_f_maxrf)[-50::1]:\n",
    "    plt.figure(figsize=(10,2))\n",
    "    plt.imshow(v4[ti_in].dropna('x', 'all').dropna('shapes', 'all'), interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.title('tin = ' + str(np.round(tin_f_maxrf[ti_in],3)) + ' k = '\n",
    "              + str(np.round(k[ti_in].values, 3)))\n",
    "    plt.xlabel('shape');plt.ylabel('pos')\n",
    "    \n",
    "    tia, u,s, v = measure_TIA(v4[ti_in], return_uv=True)\n",
    "    plt.figure(figsize=(10,2))\n",
    "    plt.imshow(s[0]*np.dot(u[:,0].reshape(len(u),1), v[0,:].reshape(1,len(v))).T,\n",
    "               interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.title('R estimate')\n",
    "    plt.xlabel('shape');plt.ylabel('pos')\n",
    "    plt.figure(figsize=(6,2))\n",
    "    plt.subplot(121);plt.plot(u[:,0]);plt.xlabel('shape');plt.ylabel('SP')\n",
    "    plt.subplot(122);plt.plot(v[0,:]*s[0]);plt.xlabel('pos');plt.ylabel('RF');plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
